{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworkFromScratchNoTF.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nic-fp/ResearchNotebooks/blob/master/NeuralNetworkFromScratchNoTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlpsPdbwQg18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1+ np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1.0 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "  def __init__(self,x,y):\n",
        "    self.input = x\n",
        "    self.weight1 = np.random(self.input.shape[1],4)\n",
        "    self.weight2 = np.random(1,4)\n",
        "    self.y = y\n",
        "    self.output = np.zeros(shape = (y.shape))\n",
        "\n",
        "  def feedforward(self):\n",
        "    self.layer1 = sigmoid(np.dot(self.x,self.weight1))\n",
        "    self.output = sigmoid(np.dot(self.layer1,self.weight2))\n",
        "\n",
        "  def backprop(self):\n",
        "    d_weights2 = np.dot(self.layer1.T,(2*(self.y,self.output) *sigmoid_derivative(self.output)))\n",
        "    d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
        "\n",
        "    self.weight1 += d_weights1\n",
        "    self.weight2 += d_weights2\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XARhQOU4Z5eU",
        "colab_type": "code",
        "outputId": "7624f976-494e-4d8c-84ad-b988403e4b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "   return 1/(1+ np.exp(-x))\n",
        "\n",
        "def intparameters(n_input,n_hidden,n_output):\n",
        "  W1 = np.random.randn(n_hidden,n_input)\n",
        "  B1 = np.zeros(shape = (n_hidden,1))\n",
        "  W2 = np.random.randn(n_output,n_hidden)\n",
        "  B2 = np.zeros(shape= [n_output])\n",
        "  parameters = {\n",
        "      \"W1\": W1,\n",
        "      \"B1\":B1,\n",
        "      \"W2\":W2,\n",
        "      \"B2\":B2,\n",
        "  }\n",
        "  return parameters\n",
        "\n",
        "def forwardprop(input,parameters):\n",
        "  W1 = parameters[\"W1\"]\n",
        "  W2 = parameters[\"W2\"]\n",
        "  B1 = parameters[\"B1\"]\n",
        "  B2 = parameters[\"B2\"]\n",
        "\n",
        "  Z1 = np.dot(W1,input) +B1\n",
        "  ActivateZ1 = np.tanh(Z1)\n",
        "  Z2 = np.dot(W2,ActivateZ1) +B2\n",
        "  ActivateZ2 = sigmoid(Z2)\n",
        "  activatedValues = {\n",
        "      \"ActivateZ1\":ActivateZ1,\n",
        "      \"ActivateZ2\": ActivateZ2\n",
        "  }\n",
        "  return ActivateZ2, activatedValues\n",
        "\n",
        "def loss(ActivateZ2,Y):\n",
        "  cost = -np.sum(np.multiply(Y, np.log(ActivateZ2)) +  np.multiply(1-Y, np.log(1-ActivateZ2)))/m\n",
        "  cost = np.squeeze(cost)\n",
        "\n",
        "  return cost\n",
        "\n",
        "def backprop(input,Y,activatedValues,parameters):\n",
        "  ActivateZ1 = activatedValues[\"ActivateZ1\"]\n",
        "  ActivateZ2 = activatedValues[\"ActivateZ2\"]\n",
        "  W2 = parameters[\"W2\"]\n",
        "  dZ2 = ActivateZ2 - Y\n",
        "  dW2 = np.dot(dZ2, ActivateZ1.T)/m\n",
        "  dB2 = np.sum(dZ2, axis=1, keepdims=True)/m\n",
        "  dZ1 = np.multiply(np.dot(W2.T, dZ2), 1-np.power(ActivateZ1, 2))\n",
        "  dW1 = np.dot(dZ1, input.T)/m\n",
        "  dB1 = np.sum(dZ1, axis=1, keepdims=True)/m\n",
        "\n",
        "  grads = {\n",
        "      \"dW1\": dW1,\n",
        "      \"dB1\": dB1,\n",
        "      \"dW2\": dW2,\n",
        "      \"dB2\": dB2\n",
        "  }\n",
        "\n",
        "  return grads\n",
        "\n",
        "def updateParameters(parameters,grads,learning_rate):\n",
        "  W1 = parameters[\"W1\"]\n",
        "  W2 = parameters[\"W2\"]\n",
        "  B1 = parameters[\"B1\"]\n",
        "  B2 = parameters[\"B2\"]\n",
        "  dW1 = grads[\"dW1\"]\n",
        "  dW2 = grads[\"dW2\"]\n",
        "  dB1 = grads[\"dB1\"]\n",
        "  dB2 = grads[\"dB2\"]\n",
        "\n",
        "  W1 = W1 -learning_rate*dW1\n",
        "  W2 = W2 -learning_rate*dW2\n",
        "  B1 = B1 -learning_rate*B1\n",
        "  B2 = B2 -learning_rate*B2\n",
        "\n",
        "  updatedParameters = {\n",
        "      \"W1\":W1,\n",
        "      \"W2\":W2,\n",
        "      \"B1\":B1,\n",
        "      \"B2\":B2,\n",
        "  }\n",
        "\n",
        "  return updatedParameters\n",
        "\n",
        "def model(input,Y,n_input,n_hidden,n_output,iterations,learning_rate):\n",
        "  parameters = intparameters(n_input,n_hidden,n_output)\n",
        "  for i in range(0,iterations+1):\n",
        "    ActivateZ2, activatedValues = forwardprop(input,parameters)\n",
        "    cost = loss(ActivateZ2,Y)\n",
        "    grads = backprop(input,Y,activatedValues,parameters)\n",
        "    parameters = updateParameters(parameters,grads,learning_rate)\n",
        "    if(i%10000 == 0):\n",
        "            print('Cost after iteration# {:d}: {:f}'.format(i, cost))\n",
        "  return parameters\n",
        "\n",
        "def predict(input, parameters):\n",
        "  ActivateZ2, activatedValues = forwardprop(input,parameters)\n",
        "  prediction = ActivateZ2\n",
        "  prediction = np.squeeze(prediction)\n",
        "  if prediction >= .5:\n",
        "    prediction =1\n",
        "  else:\n",
        "    prediction =  0\n",
        "  return prediction\n",
        "np.random.seed(2)\n",
        "\n",
        "X= np.array([[0,0,1,1],[0,1,0,1]])\n",
        "Y = np.array([[0,1,1,0]])\n",
        "m = X.shape[1]\n",
        "n_input = 2\n",
        "n_hidden = 2\n",
        "n_output =1\n",
        "iterations = 100000\n",
        "learning_rate = .9\n",
        "trainedParameters = model(X,Y,n_input,n_hidden,n_output,iterations,learning_rate)\n",
        "\n",
        "X_test = np.array([[1], [1]])\n",
        "\n",
        "y_predict = predict(X_test, trainedParameters)\n",
        "\n",
        "print('Neural Network prediction for example ({:d}, {:d}) is {:d}'.format(\n",
        "    X_test[0][0], X_test[1][0], y_predict))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration# 0: 0.856267\n",
            "Cost after iteration# 10000: 0.519861\n",
            "Cost after iteration# 20000: 0.188344\n",
            "Cost after iteration# 30000: 0.177624\n",
            "Cost after iteration# 40000: 0.175911\n",
            "Cost after iteration# 50000: 0.175178\n",
            "Cost after iteration# 60000: 0.174766\n",
            "Cost after iteration# 70000: 0.174501\n",
            "Cost after iteration# 80000: 0.174317\n",
            "Cost after iteration# 90000: 0.174181\n",
            "Cost after iteration# 100000: 0.174077\n",
            "Neural Network prediction for example (1, 1) is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGpMunMUcO8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}